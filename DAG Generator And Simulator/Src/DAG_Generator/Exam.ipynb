{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Src.DAG_Scheduler import Core\n",
    "\n",
    "core_test = Core.Core_Obj(0)\n",
    "print(core_test.Core_ID)\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  0\n",
      "test  1\n",
      "test  2\n",
      "test  3\n",
      "test  4\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def test():\n",
    "    for i in range(5):\n",
    "        print('test ',i)\n",
    "        time.sleep(1)\n",
    "\n",
    "thread = threading.Thread(target=test)\n",
    "thread.start()\n",
    "thread.join()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "'''\n",
    "自定义线程：继承threading.Thread来定义线程类，其本质是重构Thread类中的run方法\n",
    "'''\n",
    "class MyThread(threading.Thread):  # 重写threading.Thread类，加入获取返回值的函数\n",
    "    def __init__(self, param):\n",
    "        super(MyThread, self).__init__()  # (2) 重构run函数必须写\n",
    "        self.param  = param\n",
    "        self.result = 0\n",
    "\n",
    "    def run(self):\n",
    "        self.Exam_function(self.param)\n",
    "\n",
    "    def Exam_function(self, param):\n",
    "        time.sleep(int(param) / 10)\n",
    "        self.result = param\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    starrttime1 = time.time()\n",
    "    for x in range(10):\n",
    "        time.sleep(x / 10)\n",
    "        print(x)\n",
    "    endtime1 = time.time()\n",
    "\n",
    "    starrttime2 = time.time()\n",
    "\n",
    "    for x in range(10):\n",
    "        exec(f\"test{x} = MyThread(str(x))\")\n",
    "\n",
    "    for x in range(10):\n",
    "        exec(f\"test{x}.start()\")\n",
    "\n",
    "    for x in range(10):\n",
    "        exec(f\"test{x}.join()\")\n",
    "\n",
    "    print(\"***************************\")\n",
    "\n",
    "    for x in range(10):\n",
    "        exec(f\"print(format(test{x}.result))\")\n",
    "    endtime2 = time.time()\n",
    "\n",
    "    print(\"***************************\")\n",
    "    print(f\"runningtime1:{endtime1 - starrttime1}\")\n",
    "    print(f\"runningtime2:{endtime2 - starrttime2}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\begin{equation}\n",
    "    x=s_1^2$\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     DAG_type = 'DAG2_M'\n",
    "#     # DAG_addr = 'D:/github/DAG_Scheduling_Summary/Exam_Input_data/xlsx_data/wireless/DAG_Data.xlsx'\n",
    "#     rootdir = \"D:/github/DAG_Scheduling_Summary/DAG_Scheduling/Exma_code/2023-2-13-/Result_data/test/Importent_file/\"\n",
    "#     DAG_addr = DAG_type + '/core_data/'\n",
    "#     # parent:父目录; dirnames:所有文件夹名字（不含路径）; filenames:所有文件名字;\n",
    "#     file_list = os.listdir(rootdir + DAG_addr)\n",
    "#     FIFO_Core_Data_list_Summary = {}\n",
    "#     SELF_Core_Data_list_Summary = {}\n",
    "#     for file_x in file_list:\n",
    "#         if os.path.splitext(file_x)[1] == '.xlsx':\n",
    "#             # print(file_x)\n",
    "#             Core_Data_list = Core_Data_Input(rootdir + DAG_addr + file_x, 'XLSX')\n",
    "#             file_data_list = file_x.split('_')\n",
    "#             if file_data_list[0] == 'FIFO':\n",
    "#                 FIFO_Core_Data_list_Summary[file_data_list[1]] = Core_Data_list\n",
    "#             elif file_data_list[0] == 'SELF':\n",
    "#                 SELF_Core_Data_list_Summary[file_data_list[1]] = Core_Data_list\n",
    "#             else:\n",
    "#                 os.error('file name error!')\n",
    "#     data_dict = {}\n",
    "#     for key_x, value_x in FIFO_Core_Data_list_Summary.items():\n",
    "#         value_y = SELF_Core_Data_list_Summary[key_x]\n",
    "#         fifo_makespan = ret_makespan(value_x)\n",
    "#         self_makespan = ret_makespan(value_y)\n",
    "#         data_dict[key_x] = {'dag_id': key_x, 'fifo': fifo_makespan, 'self': self_makespan, 'performance': 100 * (fifo_makespan - self_makespan) / fifo_makespan}\n",
    "#     data_list = sorted(data_dict.items(), key=lambda x: x[1]['performance'], reverse=True)\n",
    "#     print(data_list[0][0])\n",
    "#     print(data_list[0][1])\n",
    "#\n",
    "#     R_fifo = FIFO_Core_Data_list_Summary[data_list[0][0]]\n",
    "#     R_self = SELF_Core_Data_list_Summary[data_list[0][0]]\n",
    "#\n",
    "#     df = pd.DataFrame({data_x[0]: {\"performance\": data_x[1]['performance'],\n",
    "#                                    'core_num': 5,\n",
    "#                                    'dag_type': DAG_type} for data_x in data_list},\n",
    "#                       index=[\"performance\", 'core_num', 'dag_type'],\n",
    "#                       columns=[data_x[0] for data_x in data_list]).T\n",
    "#     df.to_csv('./' + DAG_type + '.csv')\n",
    "#\n",
    "#     fig = plt.figure()\n",
    "#     FontSize = 12\n",
    "#\n",
    "#     ax = plt.subplot(2, 1, 1)\n",
    "#     print(\"FIFO:{0}_makespan:{1}={2}\".format(data_list[0][0], ret_makespan(R_fifo), ret_makespan(R_fifo)/2.26))\n",
    "#     SRS.show_single_dag_and_makespan_random(R_fifo, 1 * ret_makespan(R_fifo), ax, 'NS', font_size=FontSize, DAG_T=DAG_type)\n",
    "#\n",
    "#     ax = plt.subplot(2, 1, 2)\n",
    "#     print(\"FIFO:{0}_makespan:{1}={2}\".format(data_list[0][0], ret_makespan(R_self), ret_makespan(R_self)/2.26))\n",
    "#     SRS.show_single_dag_and_makespan_random(R_self, 1 * ret_makespan(R_self), ax, 'NS', font_size=FontSize, DAG_T=DAG_type)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# def Core_Data_Output(Ret_Core_Data_List, address, running_type: str, DAG_id:str):\n",
    "#     os.makedirs(address, mode=0o777, exist_ok=True)\n",
    "#     writer = pd.ExcelWriter(address + running_type + '_' + DAG_id +'__CoreData.xlsx')\n",
    "#     for core_data_x in Ret_Core_Data_List:\n",
    "#         colums_list = []\n",
    "#         data_dict = {}\n",
    "#         for task_data_id, task_data_x in enumerate(core_data_x.Core_Running_Task):\n",
    "#             colums_list.append(task_data_id)\n",
    "#             data_dict[task_data_id] = {'dag_ID': task_data_x['dag_ID'],\n",
    "#                                        'dag_NUM': task_data_x['dag_ID'],\n",
    "#                                        'node_id': task_data_x['node'][1]['Node_ID'],\n",
    "#                                        'node_Index': task_data_x['node'][1]['Node_Index'],\n",
    "#                                        'start_time': task_data_x['start_time'],\n",
    "#                                        'end_time': task_data_x['end_time'],\n",
    "#                                        'excution_time': task_data_x['end_time'] - task_data_x['start_time']}\n",
    "#         df = pd.DataFrame(data_dict, index=['dag_ID', 'dag_NUM', 'node_id', 'node_Index', 'start_time', 'end_time', 'excution_time'], columns=colums_list).T\n",
    "#         df.to_excel(writer, sheet_name=str(core_data_x.Core_ID), index=False, header=True)\n",
    "#     writer.save()\n",
    "#\n",
    "#\n",
    "# def Core_Data_CSV_Output(Ret_Core_Data_List, address, running_type: str, DAG_id: str):\n",
    "#     os.makedirs(address, mode=0o777, exist_ok=True)\n",
    "#     out_data = {}\n",
    "#     out_data_id = 0\n",
    "#     for core_data_x in Ret_Core_Data_List:\n",
    "#         for task_data_id, task_data_x in enumerate(core_data_x.Core_Running_Task):\n",
    "#             out_data[out_data_id] = { 'dag_ID': task_data_x['dag_ID'],\n",
    "#                                       'dag_NUM': task_data_x['dag_ID'],\n",
    "#                                       'node_id': task_data_x['node'][1]['Node_ID'],\n",
    "#                                       # 'node_id': task_data_x['node'][1]['JobTypeID'],\n",
    "#                                       'node_Index': task_data_x['node'][1]['Node_Index'],\n",
    "#                                       'start_time': task_data_x['start_time'],\n",
    "#                                       'end_time': task_data_x['end_time'],\n",
    "#                                       'excution_time': task_data_x['end_time'] - task_data_x['start_time'],\n",
    "#                                       'core_id': core_data_x.Core_ID}\n",
    "#             out_data_id += 1\n",
    "#     df = pd.DataFrame(out_data, index=['dag_ID', 'dag_NUM', 'node_id', 'node_Index', 'start_time', 'end_time', 'excution_time', 'core_id']).T\n",
    "#     df.to_csv(address + running_type + DAG_id +'_core.csv')\n",
    "#\n",
    "#\n",
    "#\n",
    "# def Core_Data_Input(address, file_type):\n",
    "#     if file_type == 'XLSX':\n",
    "#         Ret_Core_Data_List = []\n",
    "#         with pd.ExcelFile(address) as data:\n",
    "#             all_sheet_names = data.sheet_names\n",
    "#             for Core_ID_x in all_sheet_names:\n",
    "#                 core = Core_Obj(Core_ID_x)\n",
    "#                 df = pd.read_excel(data, Core_ID_x, index_col=None, na_values=[\"NA\"])\n",
    "#                 for row in df.index:\n",
    "#                     core.Insert_Task_Info(df.loc[row]['dag_ID'], df.loc[row]['dag_NUM'],\n",
    "#                                           (df.loc[row]['node_id'], {'Node_ID': df.loc[row]['node_Index'], 'Node_Index': df.loc[row]['node_id']}),\n",
    "#                                           df.loc[row]['start_time'], df.loc[row]['end_time'])\n",
    "#                 Ret_Core_Data_List.append(core)\n",
    "#         return Ret_Core_Data_List\n",
    "#     elif file_type == 'CSV':\n",
    "#         df = pd.read_csv(address, index_col=None, na_values=[\"NA\"])\n",
    "#         core_id_list = list(set(df['core_id']))\n",
    "#         Ret_Core_Data_dict = {Core_ID_x: Core_Obj(Core_ID_x) for Core_ID_x in core_id_list}\n",
    "#         for row in df.index:\n",
    "#             Ret_Core_Data_dict[ df.loc[row]['core_id'] ].Insert_Task_Info(\n",
    "#                     df.loc[row]['dag_ID'], df.loc[row]['dag_NUM'],\n",
    "#                     (df.loc[row]['node_id'], {'Node_ID': df.loc[row]['node_id']}),\n",
    "#                     df.loc[row]['start_time'], df.loc[row]['end_time'])\n",
    "#         Ret_Core_Data_List = [core_data_x for core_data_id, core_data_x in Ret_Core_Data_dict.items()]\n",
    "#         return Ret_Core_Data_List\n",
    "#     else:\n",
    "#         os.error('file tpye error!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mell\n",
    "## mell\n",
    "1. 第一项\n",
    "    - 第一项嵌套的第一个元素\n",
    "    - 第一项嵌套的第二个元素\n",
    "2. 第二项\n",
    "3. 第三项\n",
    "\n",
    "* 第一项\n",
    "* 第二项\n",
    "* 第三项\n",
    "\n",
    "+ 第一项\n",
    "+ 第二项\n",
    "+ 第三项\n",
    "\n",
    "\n",
    "- 第一项\n",
    "- 第二项\n",
    "- 第三项\n",
    "\n",
    "\n",
    "> 最外层\n",
    "> > 第一层嵌套\n",
    "> > > 第二层嵌套\n",
    "\n",
    "> 区块中使用列表\n",
    "> 1. 第一项\n",
    "> 2. 第二项\n",
    "> + 第一项\n",
    "> + 第二项\n",
    "> + 第三项\n",
    "\n",
    "|  表头   | 表头  |\n",
    "|  ----  | ----  |\n",
    "| 单元格  | 单元格 |\n",
    "| 单元格  | 单元格 |"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "mydemo",
   "language": "python",
   "display_name": "mydemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
